# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_0y5b0zV2rSexfGAfggjpvvvlNe7ayzK
"""

import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pylab as mplt #plotting
import numpy as np # linear algebra
import sklearn.preprocessing as sklearn
import mpl_toolkits.mplot3d as Axes3D
import seaborn as sns
import tensorflow as tensorflow
from tensorflow import keras
import os # accessing directory structure

#Read CSV files.
sales_data=pd.read_csv('/content/Retail Data Analytics/sales data-set.csv')
store_data=pd.read_csv('/content/Retail Data Analytics/stores data-set.csv')
features_data=pd.read_csv('/content/Retail Data Analytics/Features data set.csv')

#Print first 5 rows from Sales Data
print(sales_data.head(5))

#Print first 5 rows from Store Data
print(store_data.head(5))

#Print first 5 rows from features data
print(features_data.head(5))

nRow, nCol=features_data.shape
print("the features_data have", nRow, "Rows and" , nCol, "Columns")

nRow, nCol=store_data.shape
print("the store_data have", nRow, "Rows and" , nCol, "Columns")

nRow, nCol=sales_data.shape
print("the sales_data have", nRow, "Rows and" , nCol, "Columns")

features_data.info()

features_data.describe()

sales_data.info()

sales_data.describe()

store_data.info()

store_data.describe()

#Changing date format
features_data['Date']=pd.to_datetime(features_data['Date'], format='mixed')
sales_data['Date']=pd.to_datetime(sales_data['Date'], format='mixed')

#Merge two datasets
#Merge sales, and features datasets
sales_feature_df=pd.merge(sales_data, features_data, how='left', on=['Store', 'Date', 'IsHoliday'])
#merge new (sales_feature_df) dataset with store dataset
sales_store_feature_df=pd.merge(sales_feature_df, store_data, how='left', on='Store')

sales_feature_df.tail(3)

sales_store_feature_df.head(5)

sales_store_feature_df.describe(include='all')

sales_store_feature_df.info()

#Check Dataset for all null values
sales_store_feature_df.isnull().sum()

#Seperate Numerical and Categorical variables.
cat_col=['Store', 'Dept', 'IsHoliday', 'Type']
num_col=sales_store_feature_df.columns.drop(cat_col) #Drop categorical columns
num_col=num_col.drop('Date') #Drop Date columns

print('Categorical Variables')
print(cat_col)

print('Numarical Variables')
print(num_col)

#Graphical insights

#Across time: Weekly sales across time, (per month and per year), Unemployment across time, CPI across time, Fuel_Price across time, Temperature Across time
#Across outlets: Weekly sales per store, type, department
#Factors that affects sales

#Graphical insights across time.

#What is the trend in weekly sales across time - per year, per month

#Sum of sales across time.

sales_across_time=sales_store_feature_df.groupby(by =['Date'], as_index=False)['Weekly_Sales'].sum()

mplt.figure(figsize=(25, 6))
mplt.plot(sales_across_time.Date, sales_across_time.Weekly_Sales)
mplt.title("Sum of weekly sales across time")
mplt.xlabel("Date")
mplt.ylabel("Sales")
mplt.show

#sum of Yearly sales

yearly_sales=sales_store_feature_df.groupby(sales_store_feature_df.Date.dt.year)['Weekly_Sales'].sum()/1000000
sns.barplot(x=yearly_sales.index, y=yearly_sales.values, palette='viridis' )
mplt.title("Sum of weekly sales per Year")
mplt.xlabel("years")
mplt.ylabel("Sum of weekly sales (millions)")

# Sum of Monthly Sales

yearly_sales=sales_store_feature_df.groupby(sales_store_feature_df.Date.dt.month)['Weekly_Sales'].sum()/1000000
sns.barplot(x=yearly_sales.index, y=yearly_sales.values, palette='cividis' )
mplt.title("Sum of weekly sales per Month")
mplt.xlabel("Months")
mplt.ylabel("Sum of weekly sales (millions)")

# Top 5 dates where weekly_sales are the highest

sort_sales_acorss_time = sales_across_time.sort_values('Weekly_Sales', ascending=False) #Sorting in decensing order
sort_sales_acorss_time.head(5)

#What is the trend in average unemployment rate across time

#unemployment rate across time

unemployment_across_time=sales_store_feature_df.groupby(by=['Date'], as_index= False)['Unemployment'].mean()
mplt.figure(figsize=(25, 5))
mplt.plot(unemployment_across_time.Date, unemployment_across_time.Unemployment)
mplt.title("unemployment rate across time")
mplt.xlabel("Date")
mplt.ylabel("Unemployment Rate")
mplt.show

# What is the trend in average CPI across time

#CPI across time

cpi_across_time=sales_store_feature_df.groupby(by =['Date'], as_index=False)['CPI'].mean()
mplt.figure(figsize=(25, 5))
mplt.plot(cpi_across_time.Date, cpi_across_time.CPI)
mplt.title("Average CPI across time")
mplt.xlabel("Date")
mplt.ylabel("Average CPI")
mplt.show

#What is the trend in average Fuel price, Temperature across time

#Average Fuel price across time

fuel_across_time=sales_store_feature_df.groupby(by=['Date'], as_index=False)['Fuel_Price'].mean()
#print(fuel_across_time)
mplt.figure(figsize=(25,5))
mplt.plot(fuel_across_time.Date, fuel_across_time.Fuel_Price)
mplt.title("Average Fuel price across time")
mplt.xlabel("Date")
mplt.ylabel("Average Fuel Price")
mplt.show

#Average Temperature across time

tempratures_across_time=sales_store_feature_df.groupby(by= ['Date'], as_index=False)['Temperature'].mean()
mplt.figure(figsize=(25, 5))
mplt.plot(tempratures_across_time.Date, tempratures_across_time.Temperature)
mplt.title("Average Temperature across time")
mplt.xlabel("Date")
mplt.ylabel("Average Temprature")
mplt.show

# Which stores are the highest earners?

stores_sales=sales_store_feature_df.groupby(by= ['Store'], as_index=False)['Weekly_Sales'].sum()
stores_sales['Weekly_Sales']=stores_sales['Weekly_Sales']/1000000
mplt.figure(figsize=(50,10))
sns.barplot(x=stores_sales.Store, y=stores_sales.Weekly_Sales, data=stores_sales, palette='flare')
mplt.title("Sum of Weekly Sales per Store")
mplt.xlabel("Store")
mplt.ylabel("Sum of Weekly sales (millions)")
mplt.show

# Which type of store is the highest earner?
# Sum of weekly sales across Type

type_sales=sales_store_feature_df.groupby(by= ['Type'], as_index=False)['Weekly_Sales'].sum()
type_sales['Weekly_Sales']=type_sales['Weekly_Sales']/1000000
#mplt.figure(figsize=(25, 5))
sns.barplot(x=type_sales.Type, y=type_sales.Weekly_Sales, data=type_sales, palette= 'crest')
mplt.title("Sum of weekly sales across Type ")
mplt.xlabel("Type")
mplt.ylabel("Sum of Weekly sales (millions)")
mplt.show()

# Which departments are the highest earner?

department_sales=sales_store_feature_df.groupby(by= ['Dept'], as_index=False)['Weekly_Sales'].sum()
department_sales['Weekly_Sales']=department_sales['Weekly_Sales']/1000000
mplt.figure(figsize=(50, 10))
sns.barplot(x=department_sales.Dept, y=department_sales.Weekly_Sales)
mplt.title("Sum of weekly sales across Department")
mplt.xlabel("Department")
mplt.ylabel("Sum of Weekly sales (millions)")

# Trend of markdown across time
# Graphical insights on markdown

# Average Markdown across time

markdown_across_time= sales_store_feature_df.groupby('Date').agg({'MarkDown1' : 'mean', 'MarkDown2' : 'mean', 'MarkDown3' : 'mean', 'MarkDown4' : 'mean', 'MarkDown5' : 'mean',})
mplt.figure(figsize=(30,10))

mplt.plot(markdown_across_time.index, markdown_across_time.MarkDown1, label = 'MarkDown1')
mplt.plot(markdown_across_time.index, markdown_across_time.MarkDown1, label = 'MarkDown2')
mplt.plot(markdown_across_time.index, markdown_across_time.MarkDown1, label = 'MarkDown3')
mplt.plot(markdown_across_time.index, markdown_across_time.MarkDown1, label = 'MarkDown4')
mplt.plot(markdown_across_time.index, markdown_across_time.MarkDown1, label = 'MarkDown5')

mplt.title("Average Markdown across time")
mplt.xlabel("Date")
mplt.ylabel("Average MarkDown ($)")
mplt.legend(loc = 'best')

# markdown_across_month

markdown_across_month= sales_store_feature_df.groupby(sales_store_feature_df.Date.dt.month).agg({'MarkDown1' : 'mean', 'MarkDown2' : 'mean', 'MarkDown3' : 'mean', 'MarkDown4' : 'mean', 'MarkDown5' : 'mean',})
markdown_across_month.head()
markdown_across_month.plot(kind='bar', figsize=(25,10), rot=0)
mplt.xlabel("Months")
mplt.ylabel("Average markdown")
mplt.title("markdown across month")

# Frequency of markdown

markdown_across_time.hist(bins=10, figsize=(10,8), color='Green')
mplt.tight_layout()
mplt.show()

# markdown across Type

markdown_across_type= sales_store_feature_df.groupby(sales_store_feature_df.Type).agg({'MarkDown1' : 'mean', 'MarkDown2' : 'mean', 'MarkDown3' : 'mean', 'MarkDown4' : 'mean', 'MarkDown5' : 'mean',})
markdown_across_type.head()
markdown_across_type.plot(kind='bar', figsize=(25,10), rot=0)
mplt.xlabel("Type")
mplt.ylabel("Average markdown")
mplt.title("markdown across Type")

# Correlation of factors and weekly sales

mplt.figure(figsize=(15,5))
sales_store_feature_df=pd.DataFrame(sales_store_feature_df)
sales_store_feature_df=sales_feature_df.astype(float, errors='ignore')
heatmap=sns.heatmap(sales_store_feature_df.corr(), vmin=-1, vmax=1, annot=True, cmap='BrBG')
heatmap.set_title('Correlation heatmap', fontdict = {'fontsize':18}, pad=12);

# correlation of independent variables with the dependent variables (Weekly_Sales)

mplt.figure(figsize=(8,12))
heatmap=sns.heatmap(sales_store_feature_df.corr()[['Weekly_Sales']].sort_values(by='Weekly_Sales', ascending=False), vmin=-1, vmax=1, annot=True, cmap='BrBG')
heatmap.set_title('Features Correlating with Weekly Sales', fontdict={'fontsize':18}, pad =16);